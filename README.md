# ğŸ” Visual Search Engine using VLMs

A Visual Search Engine that uses Vision-Language Models (VLMs) for AI-powered image retrieval based on textual queries or sample images.

---

## ğŸ“Œ Project Overview

### ğŸ§  Problem Statement

Develop a visual search engine that leverages vision-language models (VLMs) to retrieve 
relevant images based on textual queries or sample images. The system should embed both text 
and images into a shared representation space, allowing users to search via keywords, natural 
language descriptions, or example images. 

---

## ğŸ›  Technologies Used

- **Programming Language**: Python  
- **Deep Learning Framework**: PyTorch, Torchvision  
- **Feature Extraction**: ResNet-18  
- **Web UI**: Streamlit  
- **Libraries**: NumPy, SciPy, PIL  
- **Version Control**: Git & GitHub

---

## ğŸ“Œ Features

âœ… **Image-based search** â€“ Find visually similar images from a dataset  
âœ… **Text-based search** â€“ Retrieve images using keywords or descriptions  
âœ… **Deep Learning-powered feature extraction** â€“ Uses ResNet-18 for encoding  
âœ… **Fast similarity search** â€“ Powered by precomputed image embeddings  
âœ… **Streamlit UI** â€“ Clean, user-friendly and interactive interface


---

## ğŸ“ Project Structure

<pre>

ğŸ“¦ Visual_Search_Engine_using_VLM
â”œâ”€â”€ ğŸ“‚ images/                # Sample image dataset for search
â”œâ”€â”€ ğŸ“‚ models/                # Pre-trained models or saved embeddings
â”œâ”€â”€ ğŸ“œ app.py                 # Streamlit app to run the visual search engine
â”œâ”€â”€ ğŸ“œ feature_extraction.py  # Script to extract features from images using ResNet-18
â”œâ”€â”€ ğŸ“œ search.py              # Handles similarity search (image & text-based)
â”œâ”€â”€ ğŸ“œ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“œ README.md              # Project documentation


